{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4-pwR9e2mpY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shakespeare_url = \"https://homl.info/shakespeare\"\n",
        "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "  shakespeare_text = f.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOgY-8_F2qpS",
        "outputId": "3b52ff45-ecd5-4c3d-92b9-3852fed8005c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://homl.info/shakespeare\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw2TUgU-2mpl",
        "outputId": "62090406-2d2c-4b0b-e5fc-989544bfcd9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor\n"
          ]
        }
      ],
      "source": [
        "print(shakespeare_text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text to vector conversion for encoding\n",
        "text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\", standardize=\"lower\")\n",
        "text_vec_layer.adapt([shakespeare_text])\n",
        "encoded = text_vec_layer([shakespeare_text])[0]"
      ],
      "metadata": {
        "id": "1bHsrXJC35OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing token 0 and 1\n",
        "encoded -= 2  # droping tokens 0(padding) & 1(unknown chars), which we will not use\n",
        "n_tokens = text_vec_layer.vocabulary_size() - 2 #number of distinct chars = 39\n",
        "dataset_size = len(encoded)\n",
        "print(dataset_size)\n",
        "print(len(sorted(list(set(shakespeare_text)))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLrI1gss40Gf",
        "outputId": "75b3b83d-671a-42c8-aece-b9e3ff713d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting a long sequence of character IDs into a dataset of input/target window pairs:\n",
        "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
        "  ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "  ds = ds.window(length+1, shift=1, drop_remainder=True)\n",
        "  ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=100_000, seed=seed)\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
      ],
      "metadata": {
        "id": "cKNlkn5m6xR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Training, test & Validation Set\n",
        "length = 100\n",
        "tf.random.set_seed(42)\n",
        "train_set = to_dataset(encoded[:1_00_000], length=length, shuffle=True, seed=42)\n",
        "valid_set = to_dataset(encoded[1_00_000:1_060_000], length=length)\n",
        "test_set = to_dataset(encoded[1_060_000:], length=length)"
      ],
      "metadata": {
        "id": "agm6cwA_-T15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Buildin and Training the Char-RNN Model\n",
        "# model = tf.keras.Sequential([tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
        "#                              tf.keras.layers.GRU(128, return_sequences=True),\n",
        "#                              tf.keras.layers.Dense(n_tokens, activation=\"softmax\")])\n",
        "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "# model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "#     \"my_shakespeare_model.keras\", monitor=\"val_accuracy\", save_best_only=True\n",
        "# )\n",
        "# history = model.fit(train_set, validation_data=valid_set, epochs=10, callbacks=[model_ckpt])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRehnX3DA2gP",
        "outputId": "fd9451dd-98d5-4da6-f2d3-4b8136b84034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "   3122/Unknown \u001b[1m393s\u001b[0m 116ms/step - accuracy: 0.4200 - loss: 1.9989"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for x, y in train_set.take(1):\n",
        "#     print(f\"Input shape: {x.shape}, Target shape: {y.shape}\")"
      ],
      "metadata": {
        "id": "rtsSp9hVRsBE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}